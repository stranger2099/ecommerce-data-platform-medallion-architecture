# Databricks notebook source
# MAGIC %md
# MAGIC ### Example Exploratory Notebook
# MAGIC
# MAGIC Use this notebook to explore the data generated by the pipeline in your preferred programming language.
# MAGIC
# MAGIC **Note**: This notebook is not executed as part of the pipeline.

# COMMAND ----------

import sys
from pyspark.sql.functions import *


# sys.path.append("/Workspace/Users/dssiddharth@outlook.com/ecomm_e2e_workspace/ecomm_e2e_ingestion")

# COMMAND ----------

syn_incr_load = spark.read.format("csv")\
    .option("header", "true")\
    .load("/Volumes/ecomm_e2e/ecomm_raw/raw_volume/raw_data/6b4aa196-c91d-4df2-8c2c-9019bb94fd22_synthetic_incremental_load_.csv")
print(syn_incr_load.select('Customer Id').distinct().count())
display(syn_incr_load)

# COMMAND ----------

sync_modf_load = spark.read.format("csv").option("header","true").load("/Volumes/ecomm_e2e/ecomm_raw/raw_volume/raw_data/6b4aa196-c91d-4df2-8c2c-9019bb94fd22_synthetic_incremental_load_scd2.csv")
display(sync_modf_load)
print(sync_modf_load.select('Customer Id').distinct().count())
customer_ids = sync_modf_load.select('Customer Id').distinct()


# COMMAND ----------

base_df = spark.read.format('csv').option('header',"true")\
    .load('/Volumes/ecomm_e2e/ecomm_raw/raw_volume/raw_data/DataCoSupplyChainDataset.csv')

customer_id_list = [row['Customer Id'] for row in customer_ids.collect()]
sample_df=base_df.where(col('Customer Id').isin(customer_id_list))
display(sample_df)
print(sample_df.select('Customer Id').distinct().count())

# COMMAND ----------

# !!! Before performing any data analysis, make sure to run the pipeline to materialize the sample datasets. The tables referenced in this notebook depend on that step.

display(spark.sql("SELECT * FROM ecomm_e2e.ecomm_pipeline.dimsilvercustomers"))

# COMMAND ----------

df = spark.sql("SELECT * FROM ecomm_e2e.ecomm_pipeline.dimsilvercustomers")
display(df.where(col("__END_AT").isNotNull()))

# COMMAND ----------

display(df.where(col("customer_id")==18573))

# COMMAND ----------

df = spark.sql("SELECT * FROM ecomm_e2e.ecomm_pipeline.dimsilverproducts")
display(df.where(col("__END_AT").isNotNull()))

# COMMAND ----------

display(df.where(col("product_id")==1361))

# COMMAND ----------


